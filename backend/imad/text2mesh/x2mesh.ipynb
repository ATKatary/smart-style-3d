{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X2Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess[./implementation/inputs/vase/vase7.obj is good!]: Number of verticies (12799) == the number of normals (12799)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase8.obj is good!]: Number of verticies (34846) == the number of normals (34846)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase.obj is good!]: Number of verticies (21311) == the number of normals (21311)\u001b[0m\n",
      "Found 3 working models in ./implementation/inputs/vase/.ipynb_checkpoints\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_9.obj is good!]: Number of verticies (16912) == the number of normals (16912)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_6.obj is good!]: Number of verticies (15702) == the number of normals (15702)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_4.obj is good!]: Number of verticies (18109) == the number of normals (18109)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_8.obj is good!]: Number of verticies (8942) == the number of normals (8942)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_2.obj is good!]: Number of verticies (13690) == the number of normals (13690)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_1.obj is good!]: Number of verticies (27523) == the number of normals (27523)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_7.obj is good!]: Number of verticies (8942) == the number of normals (8942)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_3.obj is good!]: Number of verticies (13469) == the number of normals (13469)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_11.obj is good!]: Number of verticies (0) == the number of normals (0)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_5.obj is good!]: Number of verticies (23303) == the number of normals (23303)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/hand/vase_hand_10.obj is good!]: Number of verticies (28671) == the number of normals (28671)\u001b[0m\n",
      "Found 14 working models in ./implementation/inputs/vase/hand\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase1.obj is good!]: Number of verticies (34846) == the number of normals (34846)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase5.obj is good!]: Number of verticies (20930) == the number of normals (20930)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase9.obj is good!]: Number of verticies (559) == the number of normals (559)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase4.obj is good!]: Number of verticies (29255) == the number of normals (29255)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase2.obj is good!]: Number of verticies (21311) == the number of normals (21311)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase3.obj is good!]: Number of verticies (9073) == the number of normals (9073)\u001b[0m\n",
      "\u001b[92mSuccess[./implementation/inputs/vase/vase6.obj is good!]: Number of verticies (16115) == the number of normals (16115)\u001b[0m\n",
      "Found 21 working models in ./implementation/inputs/vase\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from implementation.helpers import *\n",
    "\n",
    "make_prompt = lambda content, style: [f\"A very beautiful {content} made of {style}\",\n",
    "                                      f\"A {content} made of {style}\",\n",
    "                                      f\"A {style}-shaped {content}\",\n",
    "                                      f\"{content} that looks like its made of {style}\",\n",
    "                                      f\"{content} in the style of {style}\",\n",
    "                                      f\"{content} in the style of beautiful {style}\",\n",
    "                                      f\"An artistic {content} that mimics beautiful {style}\"]\n",
    "home_dir = \"./implementation\"\n",
    "text2mesh_path = \"./text2mesh\"\n",
    "models_dir = f\"{home_dir}/inputs/vase\"\n",
    "models = get_valid_models(models_dir, models={}, text2mesh_path=text2mesh_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image2Mesh Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n_aug = 2\n",
    "n_iter = 600 \n",
    "img_lr = 0.0005\n",
    "img_sigma = 2.0\n",
    "img_lr_decay = 0.9\n",
    "obj, obj_path = select_model(models)\n",
    "output_dir = \"./implementation/outputs/img2mesh/phone_holder/bark/bark\"\n",
    "img_path = f\"{output_dir}/bark1.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./implementation/old_img2mesh.sh {obj_path} {output_dir} '{img_path}' {n_iter + 1} {text2mesh_path} {home_dir} {img_sigma} {img_lr_decay} {img_lr} {img_n_aug}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_image_path = f\"{output_dir}/{obj}_iters_style_0/iter_0.jpg\"\n",
    "after_image_path = f\"{output_dir}/{obj}_iters_style_0/iter_{(n_iter // 100) * 100}.jpg\"\n",
    "\n",
    "display([before_image_path, after_image_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text2Mesh Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available models are:\n",
      "['vase7', 'vase8', 'vase', 'vase_hand_9', 'vase_hand_6', 'vase_hand_4', 'vase_hand_8', 'vase_hand_2', 'vase_hand_1', 'vase_hand_7', 'vase_hand_3', 'vase_hand_11', 'vase_hand_5', 'vase_hand_10', 'vase1', 'vase5', 'vase9', 'vase4', 'vase2', 'vase3', 'vase6']\n",
      "Name of model you want to use: vase\n"
     ]
    }
   ],
   "source": [
    "run_all = \"n\"; style = \"teracotta wood\"; content = \"vase\";\n",
    "if run_all is None: run_all = input(\"Run all? (y/n): \")\n",
    "if style is None: style = input(\"What is the style that I should test? \")\n",
    "if content is None: content = input(\"What is the content that I should test? \")\n",
    "\n",
    "batch_testing = False\n",
    "prompts = make_prompt(content, style)\n",
    "\n",
    "n_iter = 2000\n",
    "text_n_aug = 1\n",
    "text_lr = 0.002\n",
    "text_sigma = 10.0\n",
    "text_lr_decay = 0.9\n",
    "output_dir = \"./implementation/outputs/text2mesh/vase/teracotta\"\n",
    "if run_all == \"n\": \n",
    "    obj, obj_path = select_model(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccess[./implementation/inputs/vase/vase.obj is good!]: Number of verticies (21311) == the number of normals (21311)\u001b[0m\n",
      "0 to change\n",
      "Mesh Faces tensor([[11668, 17881,  2378],\n",
      "        [20174,  7149, 17873],\n",
      "        [17882, 13480, 19844],\n",
      "        ...,\n",
      "        [18775, 21309,  5380],\n",
      "        [11978, 20165,  1152],\n",
      "        [ 3881,  7051, 12232]])\n",
      "Mesh has torch.Size([21311, 3]) vertices\n",
      "100%|██████████████████████████████████| 21311/21311 [00:00<00:00, 88908.62it/s]\n",
      "Saving final output in ./implementation/outputs/text2mesh/vase/teracotta/vase_final_style_0\n",
      "Saving iters output in ./implementation/outputs/text2mesh/vase/teracotta/vase_iters_style_0\n",
      "ModuleList(\n",
      "  (0): FourierFeatureTransform()\n",
      "  (1): Linear(in_features=515, out_features=256, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (10): ReLU()\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "  0%|                                                  | 0/2001 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/ss3d/lib/python3.9/site-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 60%|███████████████████████▍               | 1200/2001 [15:55<10:08,  1.32it/s]^C\n",
      " 60%|███████████████████████▍               | 1200/2001 [15:59<10:40,  1.25it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/imad/backend/imad/text2mesh/text2mesh/main.py\", line 555, in <module>\n",
      "    \n",
      "  File \"/home/ubuntu/imad/backend/imad/text2mesh/text2mesh/main.py\", line 375, in run_branched\n",
      "    export_final_results(args, final_dir, losses, mesh, mlp, network_input, vertices, i, mask)\n",
      "  File \"/home/ubuntu/imad/backend/imad/text2mesh/text2mesh/main.py\", line 417, in export_final_results\n",
      "    objbase, extension = os.path.splitext(os.path.basename(args.obj_path))\n",
      "  File \"/home/ubuntu/imad/backend/imad/text2mesh/text2mesh/mesh.py\", line 93, in export\n",
      "    f.write(\"f %d %d %d\\n\" % (face[0] + 1, face[1] + 1, face[2] + 1))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash ./implementation/text2mesh.sh {obj_path} {output_dir} '{prompts[0]}' {n_iter + 1} {text2mesh_path} {home_dir} {text_sigma} {text_lr_decay} {text_lr} {text_n_aug}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_testing:    \n",
    "    if run_all == \"y\":\n",
    "        for obj, obj_path in models.items():\n",
    "            for prompt in prompts:\n",
    "                subprocess.call(shlex.split(f\"bash ./implementation/text2mesh.sh {obj_path} {output_dir} '{prompt}' {n_iter + 1} {text2mesh_path} {home_dir} {text_sigma} {text_lr_decay} {text_lr} {text_n_aug}\"))\n",
    "    else: \n",
    "        for prompt in prompts:\n",
    "            subprocess.call(shlex.split(f\"bash ./implementation/text2mesh.sh {obj_path} {output_dir} '{prompt}' {n_iter + 1} {text2mesh_path} {home_dir} {text_sigma} {text_lr_decay} {text_lr} {text_n_aug}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_image_path = f\"{output_dir}/{obj}_iters_style_10/iter_0.jpg\"\n",
    "after_image_path = f\"{output_dir}/{obj}_iters_style_10/iter_{(n_iter // 100) * 100}.jpg\"\n",
    "\n",
    "display([before_image_path, after_image_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cadefa720d1a2267f4d12d08d812560a64cfe891877bc388bf0e8af3e4846067"
  },
  "kernelspec": {
   "display_name": "Python3 (ss3d)",
   "language": "python",
   "name": "ss3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
